{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py-310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import pandas as pd\n",
    "from rdflib import Graph, URIRef, RDF, Namespace\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models import TransE\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.losses import MarginRankingLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference Knowledge Graph length. 675859\n",
      "Training data length. 5000\n",
      "Test data length. 2000\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "import pprint\n",
    "\n",
    "# Load reference knowledge graph\n",
    "reference_kg = Graph()\n",
    "reference_kg.parse(\"data/reference-kg.nt\", format=\"nt\")\n",
    "print(\"Reference Knowledge Graph length.\", len(reference_kg))\n",
    "\n",
    "# Load training data\n",
    "train_graph = Graph()\n",
    "train_graph.parse(\"data/fokg-sw-train-2024.nt\", format=\"nt\")\n",
    "print(\"Training data length.\", len(train_graph))\n",
    "\n",
    "#Load test data\n",
    "test_graph = Graph()\n",
    "test_graph.parse(\"data/fokg-sw-test-2024.nt\", format=\"nt\")\n",
    "print(\"Test data length.\", len(test_graph))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training TransE with reference_kg triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of triples in reference_kg:  660000\n",
      "Training TransE for 10 epochs, batch_size=256 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cpu: 100%|██████████| 10/10 [17:35<00:00, 105.51s/epoch, loss=0.0145, prev_loss=0.0147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransE model trained with reference_kg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "reference_triples = []\n",
    "for subj, pred, obj in reference_kg:\n",
    "    if isinstance(subj, rdflib.URIRef) and isinstance(obj, rdflib.URIRef): #we only consider URIRef entities\n",
    "        reference_triples.append((str(subj), str(pred), str(obj)))\n",
    "\n",
    "print(\"Number of triples in reference_kg: \",len(reference_triples))\n",
    "\n",
    "reference_triples_array = np.array(reference_triples, dtype=object)\n",
    "reference_factory = TriplesFactory.from_labeled_triples(reference_triples_array)\n",
    "\n",
    "# TransE Model\n",
    "embedding_dim = 200\n",
    "margin = 1.0\n",
    "\n",
    "model = TransE(\n",
    "    triples_factory=reference_factory,\n",
    "    embedding_dim=embedding_dim,\n",
    "    scoring_fct_norm=1,  # L1 distance\n",
    "    loss=MarginRankingLoss(margin=margin),  # margin-based ranking\n",
    "    random_seed= 42,\n",
    ")\n",
    "\n",
    "training_kg_loop = SLCWATrainingLoop(\n",
    "    model=model,\n",
    "    triples_factory=reference_factory,\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_kwargs={\"lr\": 1e-3},\n",
    "    negative_sampler=\"basic\",\n",
    "    negative_sampler_kwargs={\"num_negs_per_pos\": 10},\n",
    ")\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "print(f\"Training TransE for {num_epochs} epochs, batch_size={batch_size} ...\")\n",
    "_ = training_kg_loop.train(\n",
    "    triples_factory=reference_factory,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    use_tqdm=True,\n",
    ")\n",
    "\n",
    "print(\"TransE model trained with reference_kg.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding entity and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_to_id = reference_factory.entity_to_id\n",
    "relation_to_id = reference_factory.relation_to_id\n",
    "\n",
    "entity_representation = model.entity_representations[0]\n",
    "relation_representation = model.relation_representations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.plugins.sparql import prepareQuery\n",
    "import rdflib\n",
    "\n",
    "# Train Data\n",
    "query_train = prepareQuery(\"\"\"\n",
    "    SELECT ?stmt ?subject ?predicate ?object ?truthValue\n",
    "    WHERE {\n",
    "        ?stmt a <http://www.w3.org/1999/02/22-rdf-syntax-ns#Statement> .\n",
    "        ?stmt <http://www.w3.org/1999/02/22-rdf-syntax-ns#subject> ?subject .\n",
    "        ?stmt <http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate> ?predicate .\n",
    "        ?stmt <http://www.w3.org/1999/02/22-rdf-syntax-ns#object> ?object .\n",
    "        ?stmt <http://swc2017.aksw.org/hasTruthValue> ?truthValue .\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "train_triples = []\n",
    "train_truthValue = []\n",
    "for fact_iri, sub, pred, obj, truth_value in train_graph.query(query_train):\n",
    "    train_triples.append((sub.toPython(),pred.toPython(),obj.toPython()))\n",
    "    train_truthValue.append(truth_value.toPython())\n",
    "\n",
    "# Test Data\n",
    "query_test = prepareQuery(\"\"\"\n",
    "    SELECT ?stmt ?subject ?predicate ?object\n",
    "    WHERE {\n",
    "        ?stmt a <http://www.w3.org/1999/02/22-rdf-syntax-ns#Statement> .\n",
    "        ?stmt <http://www.w3.org/1999/02/22-rdf-syntax-ns#subject> ?subject .\n",
    "        ?stmt <http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate> ?predicate .\n",
    "        ?stmt <http://www.w3.org/1999/02/22-rdf-syntax-ns#object> ?object .\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "test_triples = []\n",
    "test_fact_iri = []\n",
    "for fact_iri, sub, pred, obj in test_graph.query(query_test):\n",
    "    test_triples.append((sub.toPython(),pred.toPython(),obj.toPython()))\n",
    "    test_fact_iri.append(fact_iri.toPython())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoded on embedded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_for_fact(subj, pred, obj):\n",
    "    if subj not in entity_to_id or obj not in entity_to_id or pred not in relation_to_id:\n",
    "        emb_dim = model.entity_representations[0]._embeddings.weight.shape[-1]\n",
    "        return np.zeros(3 * emb_dim)\n",
    "\n",
    "    s_id = entity_to_id[subj]\n",
    "    p_id = relation_to_id[pred]\n",
    "    o_id = entity_to_id[obj]\n",
    "\n",
    "    s_emb = model.entity_representations[0](indices=torch.tensor([s_id]))  # shape [1, dim]\n",
    "    p_emb = model.relation_representations[0](indices=torch.tensor([p_id]))\n",
    "    o_emb = model.entity_representations[0](indices=torch.tensor([o_id]))\n",
    "\n",
    "    cat = torch.cat([s_emb[0], p_emb[0], o_emb[0]], dim=0)\n",
    "    return cat.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "X_train = [get_embedding_for_fact(s, p, o) for (s, p, o) in train_triples]\n",
    "y_train = np.array(train_truthValue)\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "X_test = [get_embedding_for_fact(s, p, o) for (s, p, o) in test_triples]\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train a MLPClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 256, 128), activation=\"relu\", solver=\"adam\", max_iter=50, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "train_probs = mlp.predict_proba(X_train)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, train_probs)\n",
    "print(f\"Train AUC: {train_auc:.4f}\")\n",
    "\n",
    "test_probs = mlp.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write it to result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result.ttl\", \"w\") as resultFile:\n",
    "    for fact_iri, score in zip(test_fact_iri, test_probs):\n",
    "        line = f'<{fact_iri}> <http://swc2017.aksw.org/hasTruthValue> \"{score}\"^^<http://www.w3.org/2001/XMLSchema#double> .\\n'\n",
    "        resultFile.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
